{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q1: Probability Mass Function (PMF) and Probability Density Function (PDF):\n",
    "The Probability Mass Function (PMF) is used for discrete random variables. \n",
    "It gives the probability that a random variable takes on a specific value. \n",
    "The PMF is represented by P(X = x), where X is the random variable and x is a particular value.\n",
    "\n",
    "For example, consider a fair six-sided die. The PMF of rolling the die can be represented as P(X = 1) = 1/6, P(X = 2) = 1/6, ..., P(X = 6) = 1/6.\n",
    "\n",
    "The Probability Density Function (PDF) is used for continuous random variables. \n",
    "It represents the probability of a random variable falling within a specific range of values. \n",
    "The PDF is denoted as f(x), where x is a continuous variable.\n",
    "\n",
    "For example, the PDF of a standard normal distribution is represented as f(x) = (1 / sqrt(2π)) * e^(-x^2/2).\n",
    "\n",
    "Q2: Cumulative Density Function (CDF):\n",
    "The Cumulative Density Function (CDF) gives the probability that a random variable takes on a value less than or equal to a given value. \n",
    "It provides the cumulative probability up to a specific point.\n",
    "\n",
    "For example, the CDF of a continuous random variable X is denoted as F(x), where F(x) = P(X ≤ x). \n",
    "It provides the probability that X is less than or equal to x.\n",
    "\n",
    "Q3: Examples of using the normal distribution as a model:\n",
    "The normal distribution is commonly used in situations where continuous variables are involved, such as:\n",
    "\n",
    "Height and weight measurements of a population.\n",
    "Test scores in a large population.\n",
    "Errors or residuals in statistical modeling.\n",
    "Natural phenomena like the distribution of rainfall.\n",
    "The parameters of the normal distribution are the mean (μ) and standard deviation (σ). \n",
    "The mean determines the central location of the distribution, while the standard deviation controls the spread or variability. \n",
    "A larger standard deviation results in a wider and flatter distribution, \n",
    "while a smaller standard deviation leads to a narrower and taller distribution.\n",
    "\n",
    "Q4: Importance and real-life examples of the Normal Distribution:\n",
    "The normal distribution is crucial in statistics and data analysis due to its many desirable properties. Some reasons for its importance are:\n",
    "\n",
    "It serves as a baseline or reference for many statistical tests and methods.\n",
    "It simplifies analysis and allows for the use of well-established mathematical techniques.\n",
    "It is a fundamental assumption in many statistical models.\n",
    "It occurs naturally in numerous real-world phenomena.\n",
    "Real-life examples of the normal distribution include:\n",
    "\n",
    "Heights and weights of individuals in a large population.\n",
    "IQ scores in a population.\n",
    "Measurement errors in scientific experiments.\n",
    "Economic variables like stock prices and returns.\n",
    "Blood pressure measurements in a population.\n",
    "Q5: Bernoulli Distribution and the difference from Binomial Distribution:\n",
    "The Bernoulli distribution models a single binary (two possible outcomes) random variable that takes either a success or failure value, \n",
    "typically denoted as 1 and 0, respectively. \n",
    "It is characterized by a single parameter, usually denoted as p, representing the probability of success.\n",
    "\n",
    "For example, flipping a fair coin can be modeled using a Bernoulli distribution, \n",
    "where heads can be considered a success (1) and tails as a failure (0).\n",
    "\n",
    "The Binomial distribution, on the other hand, models the number of successes in a fixed number of independent Bernoulli trials. \n",
    "It is characterized by two parameters: the number of trials (n) and the probability of success in each trial (p).\n",
    "\n",
    "The main difference between the two is that the Bernoulli distribution represents a single trial, \n",
    "while the Binomial distribution represents multiple trials with a specific number of successes.\n",
    "\n",
    "Q6: Calculating the probability of a value greater than 60 in a normally distributed dataset:\n",
    "Given a normally distributed dataset with a mean of 50 and a standard deviation of 10, \n",
    "we can calculate the probability that a randomly selected observation is greater than 60 using the Z-score \n",
    "and the standard normal distribution.\n",
    "\n",
    "First, we calculate the Z-score using the formula:\n",
    "Z = (x - μ) / σ\n",
    "\n",
    "Z = (60 - 50) / 10\n",
    "Z = 1\n",
    "\n",
    "Next, we use a standard normal distribution table or statistical software to find the probability associated with a Z-score of 1. \n",
    "In this case, the probability is approximately 0.8413.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from the dataset is greater than 60 is 0.8413 or 84.13%.\n",
    "\n",
    "Q7: Uniform Distribution:\n",
    "The uniform distribution represents a continuous random variable where every value within a given interval has an equal probability of occurring. \n",
    "It has a constant probability density function (PDF) within the range of possible values.\n",
    "\n",
    "For example, consider a random variable representing the time it takes for a computer program to execute, ranging from 0 to 10 seconds. \n",
    "In a uniform distribution, any value between 0 and 10 (inclusive) has an equal probability of occurring.\n",
    "\n",
    "Q8: Z-score and its importance:\n",
    "The Z-score (or standard score) is a measure of how many standard deviations a particular value is away from the mean in a normal distribution. \n",
    "It is calculated using the formula:\n",
    "Z = (x - μ) / σ\n",
    "\n",
    "The importance of the Z-score lies in its ability to standardize values across different normal distributions. \n",
    "It allows for comparisons and assessments of relative positions or probabilities within a distribution. \n",
    "Z-scores help in determining outliers, calculating percentiles, and conducting hypothesis testing.\n",
    "\n",
    "Q9: Central Limit Theorem (CLT):\n",
    "The Central Limit Theorem states that when independent random variables are summed or averaged, \n",
    "regardless of their underlying distribution, the distribution of the sum or average tends toward a \n",
    "normal distribution as the sample size increases.\n",
    "\n",
    "The significance of the Central Limit Theorem is that it allows for the use of normal distribution-based techniques, \n",
    "even when the original data may not follow a normal distribution. It forms the basis for many statistical inference methods, \n",
    "such as hypothesis testing and confidence intervals.\n",
    "\n",
    "Q10: Assumptions of the Central Limit Theorem:\n",
    "The Central Limit Theorem relies on the following assumptions:\n",
    "\n",
    "Independence: The random variables being summed or averaged should be independent of each other.\n",
    "Sample Size: The sample size should be sufficiently large. Though there is no strict rule, \n",
    "a commonly used guideline is that the sample size should be at least 30.\n",
    "Finite Variance: The random variables should have a finite variance. \n",
    "If the variance is infinite, convergence to a normal distribution may not occur.\n",
    "These assumptions, when met, allow for the Central Limit Theorem to be applied effectively.'''"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
